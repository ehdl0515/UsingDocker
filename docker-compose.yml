version: '3.2'

services:
  MARIADB:
    image: mariadb
    ports:
      - "3306:3306"
    container_name: mariadb
    volumes:
      - ./mariadb/conf.d:/home/netis/conf.d
      - ./mariadb/data:/home/netis/data
      - ./mariadb/initdb.d:/home/netis/initdb.d
    env_file: 
      - .env
    environment:
      TZ: Asia/Seoul
    restart: always

  ORACLE12C_SLIM:
    image: store/oracle/database-enterprise:12.2.0.1-slim
    ports:
      - "1521:1521"
    container_name: oracle12c_slim
    volumes:
      - ./oracle12c:/ORCL
    environment:
      TZ: Asia/Seoul
    restart: always

  # REDIS:
  #   image: redis
  #   ports:
  #     - "16379:16379"
  #   container_name: redis
  #   volumes:
  #     - ./redis/conf.d:/home/netis/conf.d
  #     - ./redis/data:/home/netis/data
  #   hostname: redis_user
  #   # env_file:
  #   #   - .env
  #   environment:
  #     TZ: Asia/Seoul
  #   restart: always

  # POSTGRESQL:
  #   image: postgres
  #   ports:
  #     - "5252:5252"
  #   container_name: postgresql
  #   volumes:
  #     - ./postgres/data:/data
  #   environment:
  #     - POSTGRES_PASSWORD=12345

  # NGINX:
  #   image: nginx
  #   ports:
  #     - "80:80"
  #   container_name: nginx
  #   volumes:
  #     - ./nginx/data:/data

  # ZOOKEEPER:
  #   image: dydrbs159/sd-b-zookeeper
  #   ports:
  #     - "2181:2181"
  #   container_name: zookeeper

  # KAFKA:
  #   image: dydrbs159/sd-b-kafka
  #   ports:
  #     - "9092:9092"
  #   container_name: kafka
  #   environment:
  #     KAFKA_ADVERTISED_HOST_NAME: kafka1
  #     KAFKA_BROKER_ID: 1
  #     KAFKA_NUM_PARTITIONS: 5
  #     KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
  #     KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #     KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
  #     KAFKA_DELETE_TOPIC_ENABLE: "true"
  #   volumes:
  #     - /var/run/docker.sock:/var/run/docker.sock
  #   depends_on: 
  #     - ZOOKEEPER





  # logstash:
  #   image: dydrbs159/sd-b-logstash
  #   container_name: logstash
  #   volumes:
  #     - /home/adminuser/sd-b/docker/docker-elk/data/logstash_dir:/usr/share/logstash/sd_logstash
  #     - type: bind
  #       source: ./logstash/config/logstash.yml
  #       target: /usr/share/logstash/config/logstash.yml
  #       read_only: true
  #     - type: bind
  #       source: ./logstash/pipeline
  #       target: /usr/share/logstash/pipeline
  #       read_only: true
  #     - type: bind
  #       source: ./logstash/pipeline1
  #       target: /usr/share/logstash/pipeline1
  #       read_only: true
  #     - type: bind
  #       source: ./logstash/pipeline2
  #       target: /usr/share/logstash/pipeline2
  #       read_only: true
  #     - type: bind
  #       source: ./logstash/pipeline3
  #       target: /usr/share/logstash/pipeline3
  #       read_only: true
  #     - type: bind
  #       source: ./logstash/pipeline4
  #       target: /usr/share/logstash/pipeline4
  #       read_only: true
  #     - type: bind
  #       source: ./logstash/config/pipelines.yml
  #       target: /usr/share/logstash/config/pipelines.yml
  #       read_only: true

  #   ports:
  #     - "5044:5044"
  #     - "5000:5000/tcp"
  #     - "5000:5000/udp"
  #     - "9600:9600"
  #   environment:
  #     LS_JAVA_OPTS: "-Xmx1024m -Xms1024m"
  #   depends_on: 
  #     - mongodb

  
  # zoo1:
  #   image: zookeeper:3.4.9
  #   hostname: zookeeper_1
  #   ports:
  #     - "2181:2181"
  #   environment:
  #     ZOO_MY_ID: 1
  #     ZOO_PORT: 2181
  #     ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888
  #   volumes:
  #     - ./zk-multiple-kafka-multiple/zoo1/data:/data
  #     - ./zk-multiple-kafka-multiple/zoo1/datalog:/datalog
  #   container_name: zoo1

  # zoo2:
  #   image: zookeeper:3.4.9
  #   hostname: zoo2
  #   ports:
  #     - "2182:2182"
  #   environment:
  #     ZOO_MY_ID: 2
  #     ZOO_PORT: 2182
  #     ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888
  #   volumes:
  #     - ./zk-multiple-kafka-multiple/zoo2/data:/data
  #     - ./zk-multiple-kafka-multiple/zoo2/datalog:/datalog
  #   container_name: zoo2

  # zoo3:
  #   image: zookeeper:3.4.9
  #   hostname: zoo3
  #   ports:
  #     - "2183:2183"
  #   environment:
  #     ZOO_MY_ID: 3
  #     ZOO_PORT: 2183
  #     ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888
  #   volumes:
  #     - ./zk-multiple-kafka-multiple/zoo3/data:/data
  #     - ./zk-multiple-kafka-multiple/zoo3/datalog:/datalog
  #   container_name: zoo3

  # kafka:
  #   image: confluentinc/cp-kafka:5.5.1
  #   ports:
  #     - "9092:9092"
  #   environment:
  #     KAFKA_ADVERTISED_HOST_NAME: kafka
  #     KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka:19092,LISTENER_DOCKER_EXTERNAL://kafka:9092
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
  #     KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
  #     KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181,zoo2:2182,zoo3:2183"
  #     KAFKA_BROKER_ID: 1
  #     KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
  #     KAFKA_offsets_topic_replication_factor: 2
  #     KAFKA_NUM_PARTITIONS: 5
      

  #   volumes:
  #     - ./zk-multiple-kafka-multiple/kafka1/data:/var/lib/kafka/data
  #     - ./zk-multiple-kafka-multiple/kafka1/conf:/etc/kafka
  #   depends_on:
  #     - zoo1
  #     - zoo2
  #     - zoo3
  #   container_name: kafka

  # kafka2:
  #   image: confluentinc/cp-kafka:5.5.1
  #   ports:
  #     - "9093:9093"
  #   environment:
  #     KAFKA_ADVERTISED_HOST_NAME: kafka2
  #     KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka2:19093,LISTENER_DOCKER_EXTERNAL://kafka2:9093
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
  #     KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
  #     KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181,zoo2:2182,zoo3:2183"
  #     KAFKA_BROKER_ID: 2
  #     KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
  #     KAFKA_offsets_topic_replication_factor: 2
  #     KAFKA_NUM_PARTITIONS: 5

  #   volumes:
  #     - ./zk-multiple-kafka-multiple/kafka2/data:/var/lib/kafka/data
  #     - ./zk-multiple-kafka-multiple/kafka2/conf:/etc/kafka
  #   depends_on:
  #     - zoo1
  #     - zoo2
  #     - zoo3
  #   container_name: kafka2

  # kafka3:
  #   image: confluentinc/cp-kafka:5.5.1
  #   ports:
  #     - "9094:9094"
  #   environment:
  #     KAFKA_ADVERTISED_HOST_NAME: kafka3
  #     KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka3:19094,LISTENER_DOCKER_EXTERNAL://kafka3:9094
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
  #     KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
  #     KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181,zoo2:2182,zoo3:2183"
  #     KAFKA_BROKER_ID: 3
  #     KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
  #     KAFKA_offsets_topic_replication_factor: 2
  #     KAFKA_NUM_PARTITIONS: 5

  #   volumes:
  #     - ./zk-multiple-kafka-multiple/kafka3/data:/var/lib/kafka/data
  #     - ./zk-multiple-kafka-multiple/kafka3/conf:/etc/kafka
  #   depends_on:
  #     - zoo1
  #     - zoo2
  #     - zoo3
  #   container_name: kafka3



  # pyspark-jupyter:
  #   build: /home/adminuser/sd-b/docker/docker-elk/jupyter/Dockerfile
  #   image: dydrbs159/sd-b-pyspark-jupyter
  #   container_name: pyspark-jupyter
  #   volumes:
  #     - /home/adminuser/sd-b/docker/docker-elk/data:/home/jovyan/work
  #   ports:
  #     - "8888:8888"
  #   environment:
  #     LS_JAVA_OPTS: "-Xmx2048m -Xms2048m"
  #     NVIDIA_VISIBLE_DEVICES : all
  #     #NVIDIA_DRIVER_CAPABILITIES : compute,utility
      

  # mongodb:
  #   container_name: mongo
  #   image: dydrbs159/sd-b-mongodb
  #   restart: always
  #   ports:
  #     - "27017:27017"
  #   environment:
  #     MONGO_INITDB_ROOT_USERNAME: root
  #     MONGO_INITDB_ROOT_PASSWORD: "1234"

  # influxdb:
  #   image: influxdb:1.8.4
  #   container_name: influxdb
  #   volumes:
  #     - /home/adminuser/sd-b/docker/docker-elk/data/influxdb_dir:/root/.influxdbv2
  #   ports:
  #     - "8086:8086"
  #   environment:
  #     - INFLUXDB_DB=byg

  # grafana:
  #   container_name: grafana
  #   image: grafana/grafana:latest
  #   environment:
  #       - GF_INSTALL_PLUGINS=alexanderzobnin-zabbix-app
  #   volumes:
  #       - /etc/localtime:/etc/localtime:ro
  #   ports:
  #       - 3000:3000

# volumes:
#   influxdb-storage:
#   mongodb_data: